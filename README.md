# Graph Structure Reshaping Against Adversarial Attacks on Graph Neural Networks

Code implementation of the paper: [Graph Structure Reshaping Against Adversarial Attacks on Graph Neural Networks](https://ieeexplore.ieee.org/document/10538390), which has been accepted by TKDE 2024.

## Requirements
* `python 3.6.7`
* `numpy 1.15.4`
* `scipy 1.1.0`
* `scikit-learn 0.20.2`
* `matplotlib 3.0.2`
* `torch 1.0.0`
* `tqdm 4.31.1`

## Hardware Configurations
All experiments are conducted on a server with the following configurations:
* Operating System: `CentOS Linux release 7.4.1708`
* CPU: `Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.20GHz`
* GPU: `GeForce GTX TITAN X`

## Run the code
 
To try our code, you can use the IPython notebook `demo.ipynb`.

## Datasets
In the folder `./data`, we provide the following datasets:

#### Clean Graph
`cora.npz`, `citeseer.npz` and `coraml.npz`
#### Poisoned Graph Generated by Meta-Self
`[dataset]_[attack_ratio]edges_Meta-Self.npy`
#### Poisoned Graph Generated by Meta-Train
`[dataset]_[attack_ratio]edges_Meta-Train.npy`
#### Poisoned Graph Generated by Min-Max Attack
`[dataset]_[attack_ratio]_minmax.npy`

## Baselines and Adversarial Attack Methods
We use the following publicly available implementation of baseline methods and adversarial attack methods:

#### Attack Method
* Meta-Train && Meta-Self: https://github.com/danielzuegner/gnn-meta-attack
* Min-Max Attack: https://github.com/KaidiXu/GCN_ADV_Train
* NETTACK: https://github.com/danielzuegner/nettack

#### Defense Method
* RGCN: https://github.com/thumanlab/nrlweb/blob/master/static/assets/download/RGCN.zip
* VPN: https://www.dropbox.com/sh/p36pzx1ock2iamo/AABEr7FtM5nqwC4i9nICLIsta?dl=0
* LinkPred && SubGLinkPred: https://openreview.net/pdf?id=HJxdAoCcYX
* PreProcess: https://arxiv.org/pdf/1903.01610.pdf

## VisualizationÂ Example Output

![result](https://github.com/GraphReshape/GraphReshape/blob/master/result/result.png)
